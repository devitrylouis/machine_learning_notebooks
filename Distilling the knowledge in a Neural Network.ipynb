{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distilling the knowledge?\n",
    "\n",
    "Deploying machine learning algorithm has several limitations such as latency issues and high computational cost. This is usually a fundamental drawback that prevents the use of cumbersome models with good results.\n",
    "\n",
    "Our goal here is to transfer the properties of cumbersome models (i.e. great metrics) to simpler and lighter models. \n",
    "\n",
    "NOTE: This notebook is an implementation (with additional ...) of the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louisdevitry/anaconda/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We will use the popular MNSIT data set for this experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, concatenate, Activation, Conv2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.losses import categorical_crossentropy as logloss\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of the data set\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# Input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 1, 28, 28)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Numerical data\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalizing\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model configuration\n",
    "\n",
    "As suggested in the paper, several steps help our cumbersome model to make less errors:\n",
    "\n",
    "- Using a high dropout (0.5)\n",
    "- Weight constraints: One particular form of regularization was found to be especially useful for dropout— constraining the norm of the incoming weight vector at each hidden unit to be upper bounded by a fixed constant c. In other words, if w represents the vector of weights incident on any hidden unit, the neural network was optimized under the constraint ||w||_2 ≤ c. This constraint was imposed during optimization by projecting w onto the surface of a ball of radius c, whenever w went out of it. This is also called max-norm regularization since it implies that the maximum value that the norm of any weight can take is c. The constant c is a tunable hyperparameter, which is determined using a validation set. Max-norm regularization has been previously used in the context of collaborative filtering (Srebro and Shraibman, 2005). It typically improves the performance of stochastic gradient descent training of deep neural nets, even when no dropout is used.\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distillation\n",
    "\n",
    "<b>TL;DR:</b> Approximating a complex and hard to train model by a simpler one that uses the soft target of the former. \n",
    "\n",
    "## CNN basic architecture\n",
    "\n",
    "Prior to delving into the details, let's recall the basic architecture of an image classifier.\n",
    "\n",
    "![Convolutional Neural Network basic architecture](cnn_notebook.png)\n",
    "\n",
    "The inputs (the handwritten digits) pass through a Convolutional Neural Network and the following operations are performed:\n",
    "1. The convolutional and max-pooling layers creates a rich and compressed representation of the output\n",
    "2. This representation then goes into a fully-connected layer, which produce logits\n",
    "3. The softmax function converts the logits $z_{i}$ into probabilities $q_{i}$, by performing:\n",
    "\n",
    "$$ q_{i} = \\frac{exp(z_{i}/T)}{\\sum_{j}exp(z_{j}/T)} $$\n",
    "\n",
    "4. The argmax function then returns the class with the highest probability (our digits)\n",
    "\n",
    "The key takeaway before we continue is that more informations are contained in the class probabilities rather than in  the ouput digit. The idea is therefore to leverage this by constructing a simpler model that predicts the probability distribution.\n",
    "\n",
    "## Simplest form of distillation\n",
    "\n",
    "The target of the distill model are the probabilities of the cumbersome model.\n",
    "\n",
    "Train the cumbersome model with high temperature $T_{high}$ in the softmax and do the same with the distilled one. During training of the distilled model, the temperature $T_{high}$ will also be used. Once the training is done though, we set T = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "Two cumbersome models will be developed:\n",
    "- The one described in the paper\n",
    "- A more fine-tuned one\n",
    "\n",
    "We will then analyze and compare the transferatbility to lighter models on these two cumbersome models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 804s 13ms/step - loss: 0.3267 - acc: 0.9007 - val_loss: 0.0794 - val_acc: 0.9752\n",
      "Test loss: 0.07937954030409455\n",
      "Test accuracy: 0.9752\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to channels_last\n",
    "#x_train_ = np.moveaxis(x_train, -1, 0)\n",
    "#x_test_ = np.moveaxis(x_test, -1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "temperature = 5.0\n",
    "\n",
    "# remove softmax\n",
    "model_test.layers.pop()\n",
    "\n",
    "# usual probabilities\n",
    "logits = model_test.layers[-1].output\n",
    "probabilities = Activation('softmax')(logits)\n",
    "\n",
    "# softed probabilities\n",
    "logits_T = Lambda(lambda x: x/temperature)(logits)\n",
    "probabilities_T = Activation('softmax')(logits_T)\n",
    "\n",
    "output = concatenate([probabilities, probabilities_T])\n",
    "model_test = Model(model_test.input, output)\n",
    "# now model outputs 512 dimensional vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(10000, 0), dtype=float64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:, 10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss\n",
    "def knowledge_distillation_loss(y_true, y_pred, lambda_const):    \n",
    "    \n",
    "    # split in \n",
    "    #    onehot hard true targets\n",
    "    #    logits from xception\n",
    "    y_true, logits = y_true[:, :10], y_true[:, 10:]\n",
    "    \n",
    "    # convert logits to soft targets\n",
    "    y_soft = K.softmax(logits/temperature)\n",
    "    \n",
    "    # split in \n",
    "    #    usual output probabilities\n",
    "    #    probabilities made softer with temperature\n",
    "    y_pred, y_pred_soft = y_pred[:, :10], y_pred[:, 10:]    \n",
    "    \n",
    "    return lambda_const*logloss(y_true, y_pred) + logloss(y_soft, y_pred_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return categorical_accuracy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_5_accuracy(y_true, y_pred):\n",
    "    y_true = y_true[:, :10]\n",
    "    y_pred = y_pred[:, :10]\n",
    "    return top_k_categorical_accuracy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_crossentropy(y_true, y_pred):\n",
    "    y_true = y_true[:, 10:]\n",
    "    y_pred = y_pred[:, 10:]\n",
    "    return logloss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logloss with only soft probabilities and targets\n",
    "def soft_logloss(y_true, y_pred):     \n",
    "    logits = y_true[:, 10:]\n",
    "    y_soft = K.softmax(logits/temperature)\n",
    "    y_pred_soft = y_pred[:, 10:]    \n",
    "    return logloss(y_soft, y_pred_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'get_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-85445d405686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msoft_logloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-66a3dcee4b46>\u001b[0m in \u001b[0;36msoft_logloss\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my_soft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_pred_soft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlogloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_soft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_soft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/losses.pyc\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits)\u001b[0m\n\u001b[1;32m   2854\u001b[0m         \u001b[0;31m# scale preds so that the class probas of each sample sum to 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2855\u001b[0m         output /= tf.reduce_sum(output,\n\u001b[0;32m-> 2856\u001b[0;31m                                 \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2857\u001b[0m                                 keep_dims=True)\n\u001b[1;32m   2858\u001b[0m         \u001b[0;31m# manual computation of crossentropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'get_shape'"
     ]
    }
   ],
   "source": [
    "soft_logloss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 28, 28)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_ = x_train.reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 28, 28)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [128,0] vs. [128,246]\n\t [[Node: training_12/SGD/gradients/loss_12/concatenate_1_loss/mul_2_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _class=[\"loc:@loss_12/concatenate_1_loss/mul_2\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](training_12/SGD/gradients/loss_12/concatenate_1_loss/mul_2_grad/Shape, training_12/SGD/gradients/loss_12/concatenate_1_loss/mul_2_grad/Shape_1)]]\n\nCaused by op u'training_12/SGD/gradients/loss_12/concatenate_1_loss/mul_2_grad/BroadcastGradientArgs', defined at:\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 389, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 151, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tornado/ioloop.py\", line 866, in start\n    handler_func(fd_obj, events)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 433, in _handle_events\n    self._handle_recv()\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 465, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 252, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 213, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 362, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3012, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-72-b2601425dd21>\", line 11, in <module>\n    validation_data=(x_test, y_test))\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/engine/training.py\", line 1608, in fit\n    self._make_train_function()\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/engine/training.py\", line 990, in _make_train_function\n    loss=self.total_loss)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/optimizers.py\", line 156, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/optimizers.py\", line 73, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 2369, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 482, in gradients\n    in_grads = grad_fn(op, *out_grads)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py\", line 610, in _MulGrad\n    rx, ry = gen_array_ops._broadcast_gradient_args(sx, sy)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 411, in _broadcast_gradient_args\n    name=name)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op u'loss_12/concatenate_1_loss/mul_2', defined at:\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n[elided 15 identical lines from previous traceback]\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-72-b2601425dd21>\", line 5, in <module>\n    metrics=['accuracy'])\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/engine/training.py\", line 860, in compile\n    sample_weight, mask)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/engine/training.py\", line 460, in weighted\n    score_array = fn(y_true, y_pred)\n  File \"<ipython-input-72-b2601425dd21>\", line 3, in <lambda>\n    model_test.compile(loss=lambda y_true, y_pred: knowledge_distillation_loss(y_true, y_pred, lambda_const),\n  File \"<ipython-input-67-4c2759a7b93e>\", line 17, in knowledge_distillation_loss\n    return lambda_const*logloss(y_true, y_pred) + logloss(y_soft, y_pred_soft)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/losses.py\", line 50, in categorical_crossentropy\n    return K.categorical_crossentropy(y_true, y_pred)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 2861, in categorical_crossentropy\n    return - tf.reduce_sum(target * tf.log(output),\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 884, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 1105, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1625, in _mul\n    result = _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [128,0] vs. [128,246]\n\t [[Node: training_12/SGD/gradients/loss_12/concatenate_1_loss/mul_2_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _class=[\"loc:@loss_12/concatenate_1_loss/mul_2\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](training_12/SGD/gradients/loss_12/concatenate_1_loss/mul_2_grad/Shape, training_12/SGD/gradients/loss_12/concatenate_1_loss/mul_2_grad/Shape_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-b2601425dd21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m               validation_data=(x_test, y_test))\n\u001b[0m",
      "\u001b[0;32m/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [128,0] vs. [128,246]\n\t [[Node: training_12/SGD/gradients/loss_12/concatenate_1_loss/mul_2_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _class=[\"loc:@loss_12/concatenate_1_loss/mul_2\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](training_12/SGD/gradients/loss_12/concatenate_1_loss/mul_2_grad/Shape, training_12/SGD/gradients/loss_12/concatenate_1_loss/mul_2_grad/Shape_1)]]\n\nCaused by op u'training_12/SGD/gradients/loss_12/concatenate_1_loss/mul_2_grad/BroadcastGradientArgs', defined at:\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 389, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 151, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tornado/ioloop.py\", line 866, in start\n    handler_func(fd_obj, events)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 433, in _handle_events\n    self._handle_recv()\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 465, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 252, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 213, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 362, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3012, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-72-b2601425dd21>\", line 11, in <module>\n    validation_data=(x_test, y_test))\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/engine/training.py\", line 1608, in fit\n    self._make_train_function()\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/engine/training.py\", line 990, in _make_train_function\n    loss=self.total_loss)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/optimizers.py\", line 156, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/optimizers.py\", line 73, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 2369, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 482, in gradients\n    in_grads = grad_fn(op, *out_grads)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py\", line 610, in _MulGrad\n    rx, ry = gen_array_ops._broadcast_gradient_args(sx, sy)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 411, in _broadcast_gradient_args\n    name=name)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op u'loss_12/concatenate_1_loss/mul_2', defined at:\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n[elided 15 identical lines from previous traceback]\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-72-b2601425dd21>\", line 5, in <module>\n    metrics=['accuracy'])\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/engine/training.py\", line 860, in compile\n    sample_weight, mask)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/engine/training.py\", line 460, in weighted\n    score_array = fn(y_true, y_pred)\n  File \"<ipython-input-72-b2601425dd21>\", line 3, in <lambda>\n    model_test.compile(loss=lambda y_true, y_pred: knowledge_distillation_loss(y_true, y_pred, lambda_const),\n  File \"<ipython-input-67-4c2759a7b93e>\", line 17, in knowledge_distillation_loss\n    return lambda_const*logloss(y_true, y_pred) + logloss(y_soft, y_pred_soft)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/losses.py\", line 50, in categorical_crossentropy\n    return K.categorical_crossentropy(y_true, y_pred)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 2861, in categorical_crossentropy\n    return - tf.reduce_sum(target * tf.log(output),\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 884, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 1105, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1625, in _mul\n    result = _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/Users/louisdevitry/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [128,0] vs. [128,246]\n\t [[Node: training_12/SGD/gradients/loss_12/concatenate_1_loss/mul_2_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _class=[\"loc:@loss_12/concatenate_1_loss/mul_2\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](training_12/SGD/gradients/loss_12/concatenate_1_loss/mul_2_grad/Shape, training_12/SGD/gradients/loss_12/concatenate_1_loss/mul_2_grad/Shape_1)]]\n"
     ]
    }
   ],
   "source": [
    "lambda_const = 0.07\n",
    "\n",
    "model_test.compile(loss=lambda y_true, y_pred: knowledge_distillation_loss(y_true, y_pred, lambda_const),\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-1, momentum=0.9, nesterov=True), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_test.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=1,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 249s 4ms/step - loss: 0.2994 - acc: 0.9083 - val_loss: 0.0877 - val_acc: 0.9688\n",
      "Test loss: 0.0876760777818039\n",
      "Test accuracy: 0.9688\n"
     ]
    }
   ],
   "source": [
    "from keras.losses import categorical_crossentropy as logloss\n",
    "\n",
    "def knowledge_distillation_loss(y_true, y_pred, lambda_const = 6):    \n",
    "    \n",
    "    # split in \n",
    "    #    onehot hard true targets\n",
    "    #    logits from xception\n",
    "    y_true, logits = y_true[:, :256], y_true[:, 256:]\n",
    "    \n",
    "    # convert logits to soft targets\n",
    "    y_soft = K.softmax(logits/temperature)\n",
    "    \n",
    "    # split in \n",
    "    #    usual output probabilities\n",
    "    #    probabilities made softer with temperature\n",
    "    y_pred, y_pred_soft = y_pred[:, :256], y_pred[:, 256:]    \n",
    "    \n",
    "    return lambda_const*logloss(y_true, y_pred) + logloss(y_soft, y_pred_soft)\n",
    "\n",
    "# Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=loss,#keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, probas,\n",
    "          batch_size=batch_size,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_test = model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 1.1292136 , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.8081301 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.9808517 , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.25781712,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources:\n",
    "\n",
    "https://arxiv.org/pdf/1503.02531.pdf\n",
    "http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf\n",
    "https://arxiv.org/pdf/1207.0580.pdf\n",
    "https://cambridgespark.com/content/tutorials/neural-networks-tuning-techniques/index.html\n",
    "https://en.wikipedia.org/wiki/Softmax_function\n",
    "https://www.quora.com/What-does-Dr-Hinton-mean-by-hard-vs-soft-targets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
